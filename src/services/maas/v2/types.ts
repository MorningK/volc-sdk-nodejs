export type ServiceOptions = {
  host?: string;
  region?: string;
  timeout?: number;
};

interface IFunction {
  name: string;
  description: string;
  parameters?: Record<string, any>;
  examples?: string[];
}

export interface Tool {
  type: string;
  function: IFunction;
}

export interface FunctionCall {
  // The name of the function to call.
  name: string;

  // The arguments to call the function with, generated by model, formatted as json, may not valid,
  // the caller should validate the arguments before calling the function.
  arguments: string;
}

export interface ToolCall {
  Function: FunctionCall;
  id: string;
  type: string;
}

export enum ChatRole {
  User = "user",
  Assistant = "assistant",
  System = "system",
  Function = "function",
}

export interface Reference {
  // url
  url: string;

  // the index of url
  idx: number;

  // the logo of url
  logo_url: string;

  // the url be used for pc
  pc_url: string;

  // the topic of url
  site_name: string;
}

export interface Message {
  content: string;
  name?: string;
  references?: Reference[];
  role: ChatRole;
  tool_call_id?: string;
  tool_calls?: ToolCall[];
}

export interface Parameters {
  // Exponential scaling output probability distribution
  temperature?: number;

  // The maximum number of tokens to generate in the char completion.
  max_tokens?: number;

  // An alternative to sampling with temperature, called nucleus sampling,
  // where the model considers the results of the tokens with top_p probability
  // mass
  top_p?: number;

  // Number between -2.0 and 2.0. Positive values penalize new tokens based
  // on whether they appear in the text so far, increasing the model's
  // likelihood to talk about new topics.
  presence_penalty?: number;

  // Number between -2.0 and 2.0. Positive values penalize new tokens based on
  // their existing frequency in the text so far, decreasing the model's
  // likelihood to repeat the same line verbatim.
  frequency_penalty?: number;

  // The maximum number of tokens to generate, ignoring the number of tokens in
  // the prompt
  max_new_tokens?: number;

  // The parameter for repetition penalty, from [1.0, 2.0]
  repetition_penalty?: number;

  // Whether or not to use sampling, use greedy decoding otherwise. Default to
  // false
  do_sample?: boolean;

  // The number of highest probability vocabulary tokens to keep for
  // top-k-filtering.
  top_k?: number;

  // the minimum number of tokens to generate
  min_new_tokens?: number;

  // the maximum number of prompt tokens, if prompt tokens length over this
  // limit, it will be truncated as prompt[-max_prompt_tokens:]
  max_prompt_tokens?: number;

  logprobs?: number;
}

export interface ChatReq {
  crypto_token?: string;
  extra?: Record<string, any>;
  messages: Message[];
  parameters?: Parameters;
  stream?: boolean;
  tools?: Tool[];
  user?: string;
}

interface ChoiceLog {
  content: string;
  input: string;
}

interface Logprobs {
  text_offset: number[];
  token_logprobs: number[];
  tokens: string[];
  top_logprobs: Record<string, any>[];
}

export interface Choice {
  index?: number;
  message?: Message;
  finish_reason?: string;
  action?: ChoiceLog;
  logprobs?: Logprobs;
  observation?: ChoiceLog;
  thought?: ChoiceLog;
}

export interface Usage {
  // The number of prompt tokens
  prompt_tokens: number;

  // The number of generated tokens
  completion_tokens: number;

  // The number of all: prompt_tokens + completion_tokens
  total_tokens: number;
}

export interface Error {
  code: string;
  code_n: number;
  message: string;
}

export interface ChatResp {
  req_id?: string;
  error?: Error;
  choices?: Choice[];
  usage?: Usage;
  extra?: { [key: string]: string };
}

export interface TokenizeReq {
  text: string;
}

export interface TokenizeResp {
  req_id: string;
  error?: Error;
  tokens: string[];
  total_tokens: number;
}

export interface ClassificationReq {
  labels: string[];
  query: string;
}
export interface LabelLogprobosValue {
  req_id?: string;
  tokens: string[];
  token_logprobos: string[];
}

export interface ClassificationResp {
  req_id: string;
  error?: Error;
  label: string;
  label_logprobos: Record<string, LabelLogprobosValue>;
  usage?: Usage;
}

export interface EmbeddingsReq {
  input: string[];
}

export interface Embedding {
  index?: number;
  embedding: number[];
  object: string;
}

export interface EmbeddingsResp {
  req_id?: string;
  object?: string;
  data: Embedding[];
  usage?: Usage;
  error?: Error;
}
